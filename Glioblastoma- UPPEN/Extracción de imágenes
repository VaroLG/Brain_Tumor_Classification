Extracci칩n de Im치genes MRI de Glioblastomas (Dataset UPENN - TCIA)
游닂 Descripci칩n general

Este proyecto forma parte de mi trabajo final de master sobre la clasificaci칩n de im치genes de resonancia magn칠tica nuclear (RMN) de tumores cerebrales mediante t칠cnicas de Deep Learning.
El objetivo principal es procesar y extraer cortes bidimensionales (2D) de las im치genes MRI en formato NIfTI pertenecientes al dataset p칰blico de glioblastomas de la Universidad de Pensilvania (UPENN, disponible en TCIA), con el fin de preparar las im치genes para modelos de segmentaci칩n y clasificaci칩n.

游빌 Objetivos espec칤ficos

Cargar las im치genes de resonancia magn칠tica en formato NIfTI (.nii/.gz).
Extraer las slices 2D relevantes de cada volumen tridimensional.
Guardar las im치genes resultantes en formato PNG, organizadas por:
- Paciente
- Modalidad (T1, T2, FLAIR, etc.)
- Orientaci칩n (axial, coronal, sagital)
- Asegurar una estructura clara y reutilizable para entrenamientos posteriores con modelos de IA.

Metodolog칤a y estructura del notebook:

1. Importaci칩n de librer칤as necesarias para la lectura, manejo y visualizaci칩n de im치genes m칠dicas y configuraci칩n del entorno y se cargan las librer칤as:

import nibabel as nib
import os
import matplotlib.pyplot as plt
import numpy as np


Estas librer칤as permiten manipular im치genes en formato NIfTI y realizar operaciones de conversi칩n y guardado.

2. Definici칩n de rutas de trabajo

Se establecen las rutas locales hacia los directorios donde se encuentran los archivos NIfTI descargados del dataset UPENN, as칤 como el destino donde se guardar치n las im치genes procesadas.

3. Lectura y exploraci칩n de los archivos NIfTI

En esta etapa se abre cada imagen NIfTI y se inspeccionan sus dimensiones para determinar el n칰mero de slices disponibles por orientaci칩n (axial, coronal, sagital).
Se utiliza nibabel.load() para leer cada archivo y get_fdata() para obtener la matriz de intensidades.

4. Extracci칩n de cortes (slices) 2D

El c칩digo recorre cada volumen tridimensional y extrae im치genes 2D (slices).
Dependiendo de la orientaci칩n seleccionada (axial, coronal o sagital), se aplican distintos 칤ndices sobre el array de voxeles:

slice_img = volume[:, :, slice_index]


Cada slice se normaliza para mejorar la visualizaci칩n y posteriormente se convierte a formato de imagen (PNG).

5. Visualizaci칩n y verificaci칩n de cortes

Antes de guardar todas las im치genes, se visualizan algunos cortes con matplotlib para verificar que la extracci칩n se ha realizado correctamente.
Esto permite comprobar la orientaci칩n, contraste y presencia de la lesi칩n tumoral.

6. Guardado estructurado de im치genes en formato PNG

Cada imagen se guarda en carpetas organizadas por paciente, modalidad y orientaci칩n:

/Output/UPENN-GBM-00629/FLAIR/sagittal/slice_122.png

Los nombres de los archivos incluyen informaci칩n relevante sobre el paciente, como el identificador del paciente, la modalidad de imagen, la orientaci칩n y el n칰mero de corte, lo cual permite enlazar f치cilmente cada imagen con sus metadatos cl칤nicos.
UPENN-GBM-00629_21_FLAIR_sagittal_slice_122.png

7. Automatizaci칩n del proceso

El script est치 dise침ado para procesar autom치ticamente todos los pacientes del conjunto, generando una base de datos visual completa y homog칠nea para etapas posteriores de entrenamiento con modelos de segmentaci칩n o clasificaci칩n.

游 Aplicaciones futuras

Entrenamiento de modelos de Deep Learning para segmentaci칩n tumoral.

Clasificaci칩n de pacientes seg칰n supervivencia o mutaciones moleculares.

Integraci칩n con datos cl칤nicos o gen칩micos para an치lisis multimodal.
