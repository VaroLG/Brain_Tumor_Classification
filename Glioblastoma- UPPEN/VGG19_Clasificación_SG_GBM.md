ClasificaciÃ³n de Glioblastoma Multiforme (GBM) por Supervivencia Global (SG) usando CNN (VGG19)

ğŸ“„ Resumen del Proyecto
Este proyecto se centra en la aplicaciÃ³n de una Red Neuronal Convolucional (CNN) preentrenada, especÃ­ficamente VGG19, mediante la tÃ©cnica de Transfer Learning, para clasificar imÃ¡genes de Glioblastoma Multiforme (GBM) basÃ¡ndose en la Supervivencia Global (SG) del paciente.

El objetivo es entrenar un modelo para distinguir entre:

SG alta: Supervivencia Global alta.

SG baja: Supervivencia Global baja.

El cÃ³digo aborda la carga de datos, el aumento de datos (data augmentation), la construcciÃ³n del modelo VGG19 (ajustando la capa densa de salida), y el entrenamiento del modelo.

ğŸ› ï¸ Requisitos e InstalaciÃ³n
AsegÃºrate de tener un entorno Python 3 con las siguientes librerÃ­as instaladas. Se recomienda usar pip para su instalaciÃ³n:

Bash

pip install tensorflow
pip install keras
pip install numpy
pip install matplotlib
Requisitos Adicionales
El entrenamiento del modelo VGG19 es intensivo y se beneficia enormemente de una GPU con soporte para CUDA.

ğŸ“‚ Estructura del Directorio de Datos
Este proyecto asume que los datos de las imÃ¡genes ya han sido divididos en conjuntos de entrenamiento, validaciÃ³n y prueba, organizados por las etiquetas (SG alta y SG baja).

La estructura esperada del directorio base (dir) es la siguiente:

dir/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ SG alta/      # ImÃ¡genes para entrenamiento
â”‚   â””â”€â”€ SG baja/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ SG alta/      # ImÃ¡genes para validaciÃ³n
â”‚   â””â”€â”€ SG baja/
â””â”€â”€ test/
    â”œâ”€â”€ SG alta/      # ImÃ¡genes para prueba
    â””â”€â”€ SG baja/
ConfiguraciÃ³n de Rutas
AsegÃºrate de configurar la variable dir en tu notebook para que apunte a la ruta base de tus datos:

Python

dir = r"C:\\ruta\\a\\tu\\directorio\\de\\imagenes\\de\\Glioma_clasificaciÃ³n"

ConfiguraciÃ³n del Modelo y Entrenamiento
1. Preprocesamiento y Data Augmentation
Se utiliza ImageDataGenerator de Keras para:

Normalizar los valores de pÃ­xeles (reescalando a [0,1]).

Aumentar los datos en el conjunto de entrenamiento mediante rotaciones, cambios de ancho/alto, cizallamiento y zoom, para mejorar la robustez del modelo.

Cargar las imÃ¡genes directamente desde la estructura de directorios.

Las imÃ¡genes se configuran con un tamaÃ±o de 224Ã—224 pÃ­xeles, adecuado para VGG19.

2. ConstrucciÃ³n del Modelo
El modelo se construye mediante Transfer Learning:

Se carga la arquitectura base de VGG19, preentrenada con el dataset ImageNet, y se congelan sus capas convolucionales (base_model.trainable = False).

Se aÃ±ade una capa de aplanamiento (Flatten).

Se aÃ±ade una capa densa (Dense) con una funciÃ³n de activaciÃ³n ReLU.

Se aÃ±ade la capa de salida (Dense) con 2 unidades (una por clase: SG alta/baja) y activaciÃ³n Softmax.

3. CompilaciÃ³n y Entrenamiento
El modelo se compila con:

Optimizador: Adam.

FunciÃ³n de PÃ©rdida: categorical_crossentropy (apropiada para clasificaciÃ³n multiclase).

MÃ©trica: accuracy.

El entrenamiento se realiza durante un nÃºmero definido de Ã©pocas, utilizando fit_generator para iterar sobre los datos generados.

EvaluaciÃ³n de Resultados
Una vez completado el entrenamiento, el modelo debe ser evaluado en el conjunto de prueba (test_generator) para determinar su rendimiento en datos no vistos. Los resultados de pÃ©rdida y precisiÃ³n se reportarÃ¡n para validar la capacidad de clasificaciÃ³n del modelo VGG19.
Contribuciones
SiÃ©ntete libre de clonar este repositorio, experimentar con diferentes arquitecturas de CNN (como ResNet o EfficientNet), ajustar los hiperparÃ¡metros, o sugerir mejoras en el preprocesamiento de imÃ¡genes.
